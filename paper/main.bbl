\begin{thebibliography}{10}

\bibitem{naveed2024comprehensive}
H.~Naveed, A.~U. Khan, S.~Qiu, M.~Saqib, S.~Anwar, M.~Usman, N.~Akhtar,
  N.~Barnes, and A.~Mian, ``A comprehensive overview of large language
  models,'' 2024.

\bibitem{dosovitskiy2021image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, J.~Uszkoreit,
  and N.~Houlsby, ``An image is worth 16x16 words: Transformers for image
  recognition at scale,'' 2021.

\bibitem{ronneberger2015unet}
O.~Ronneberger, P.~Fischer, and T.~Brox, ``U-net: Convolutional networks for
  biomedical image segmentation,'' 2015.

\bibitem{he2015deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' 2015.

\bibitem{vaswani2023attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  L.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' 2023.

\bibitem{choromanski2022rethinking}
K.~Choromanski, V.~Likhosherstov, D.~Dohan, X.~Song, A.~Gane, T.~Sarlos,
  P.~Hawkins, J.~Davis, A.~Mohiuddin, L.~Kaiser, D.~Belanger, L.~Colwell, and
  A.~Weller, ``Rethinking attention with performers,'' 2022.

\bibitem{gu2022efficiently}
A.~Gu, K.~Goel, and C.~Ré, ``Efficiently modeling long sequences with
  structured state spaces,'' 2022.

\bibitem{gu2023mamba}
A.~Gu and T.~Dao, ``Mamba: Linear-time sequence modeling with selective state
  spaces,'' 2023.

\bibitem{lecundocument}
Y.~Lecun, L.~Bottou, Y.~Bengio, and P.~Haffner, ``Gradient-based learning
  applied to document recognition,'' {\em Proceedings of the IEEE}, vol.~86,
  pp.~2278 -- 2324, 12 1998.

\bibitem{krizhevsky2012imagenet}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton, ``Imagenet classification with
  deep convolutional neural networks,'' in {\em Advances in Neural Information
  Processing Systems} (F.~Pereira, C.~Burges, L.~Bottou, and K.~Weinberger,
  eds.), vol.~25, Curran Associates, Inc., 2012.

\bibitem{simonyan2014deep}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for
  large-scale image recognition,'' 2015.

\bibitem{szegedy2015going}
C.~Szegedy, W.~Liu, Y.~Jia, P.~Sermanet, S.~Reed, D.~Anguelov, D.~Erhan,
  V.~Vanhoucke, and A.~Rabinovich, ``Going deeper with convolutions,'' 2014.

\bibitem{howard2017mobilenets}
A.~G. Howard, M.~Zhu, B.~Chen, D.~Kalenichenko, W.~Wang, T.~Weyand,
  M.~Andreetto, and H.~Adam, ``Mobilenets: Efficient convolutional neural
  networks for mobile vision applications,'' 2017.

\bibitem{tan2020efficientnet}
M.~Tan and Q.~V. Le, ``Efficientnet: Rethinking model scaling for convolutional
  neural networks,'' 2020.

\bibitem{radosavovic2020designing}
I.~Radosavovic, R.~P. Kosaraju, R.~Girshick, K.~He, and P.~Dollár, ``Designing
  network design spaces,'' 2020.

\bibitem{xie2021segformer}
E.~Xie, W.~Wang, Z.~Yu, A.~Anandkumar, J.~M. Alvarez, and P.~Luo, ``Segformer:
  Simple and efficient design for semantic segmentation with transformers,''
  2021.

\bibitem{cheng2017survey}
Y.~Cheng, D.~Wang, P.~Zhou, and T.~Zhang, ``A survey of model compression and
  acceleration for deep neural networks,'' 2020.

\bibitem{hinton2015distilling}
G.~Hinton, O.~Vinyals, and J.~Dean, ``Distilling the knowledge in a neural
  network,'' 2015.

\bibitem{Jamil}
U.~Jamil, ``Hkproj/mamba-notes: Notes on the mamba and the s4 model (mamba:
  Linear-time sequence modeling with selective state spaces).''

\bibitem{gu2020hippo}
A.~Gu, T.~Dao, S.~Ermon, A.~Rudra, and C.~Re, ``Hippo: Recurrent memory with
  optimal polynomial projections,'' 2020.

\bibitem{ma2024umamba}
J.~Ma, F.~Li, and B.~Wang, ``U-mamba: Enhancing long-range dependency for
  biomedical image segmentation,'' 2024.

\bibitem{ho2020denoising}
J.~Ho, A.~Jain, and P.~Abbeel, ``Denoising diffusion probabilistic models,''
  2020.

\bibitem{rombach2022highresolution}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer, ``High-resolution
  image synthesis with latent diffusion models,'' 2022.

\bibitem{wu2024ultralight}
R.~Wu, Y.~Liu, P.~Liang, and Q.~Chang, ``Ultralight vm-unet: Parallel vision
  mamba significantly reduces parameters for skin lesion segmentation,'' 2024.

\bibitem{dataset}
M.~Buda, ``Brain mri segmentation,'' May 2019.

\bibitem{zhao2017pyramid}
H.~Zhao, J.~Shi, X.~Qi, X.~Wang, and J.~Jia, ``Pyramid scene parsing network,''
  2017.

\bibitem{CIFAR-10}


\bibitem{zhu2024vision}
L.~Zhu, B.~Liao, Q.~Zhang, X.~Wang, W.~Liu, and X.~Wang, ``Vision mamba:
  Efficient visual representation learning with bidirectional state space
  model,'' 2024.

\end{thebibliography}
